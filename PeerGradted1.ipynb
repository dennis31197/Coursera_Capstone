{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  This notebook is for the Capstone Project of the Coursera course Applied Data Science\n",
    "** First the postcodes of Toronto will be scraped from a wikipeda page. This data will be stored and processed into a Data Frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the HTML code from the wikipedia website with the postcodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the html code from the respective website\n",
    "page = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\n",
    "#store the html file in the soup variable with the lxml parser\n",
    "soup = BeautifulSoup(page, 'lxml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize some empty lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some variables\n",
    "columns_headers = []\n",
    "values_column1 = []\n",
    "values_column2 = []\n",
    "values_column3 = []\n",
    "filter_DF =[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Scrape the webpage. We will get the name for the columns as well as the data for each row from the HTML code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the relevent div from the whole soup\n",
    "source = soup.find('div', class_='mw-parser-output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for all entries in the first row of the table (the headings)\n",
    "for tr in source.find_all('tr')[0].find_all('th'):\n",
    "    columns_headers.append(tr.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the last heading has a \\n at the end, we have the cut it away\n",
    "columns_headers[2] = columns_headers[2][0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the table to get all the entries for the columns\n",
    "for td in source.find_all('td')[::3]:\n",
    "    values_column1.append(td.text)\n",
    "for td in source.find_all('td')[1::3]:\n",
    "    values_column2.append(td.text)    \n",
    "for td in source.find_all('td')[2::3]:\n",
    "    values_column3.append(td.text)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'M9Z' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-522-2192997769b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# because there is some extra code that is not part of the table we have to get rid of the irrelevant entries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrelevant_number_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues_column1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'M9Z'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvalues_column1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues_column1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrelevant_number_rows\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvalues_column2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues_column2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrelevant_number_rows\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvalues_column3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues_column3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrelevant_number_rows\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'M9Z' is not in list"
     ]
    }
   ],
   "source": [
    "# because there is some extra code that is not part of the table we have to get rid of the irrelevant entries\n",
    "relevant_number_rows = values_column1.index('M9Z')\n",
    "values_column1 = values_column1[0:relevant_number_rows+1]\n",
    "values_column2 = values_column2[0:relevant_number_rows+1]\n",
    "values_column3 = values_column3[0:relevant_number_rows+1]\n",
    "\n",
    "#again in column 3 there is a /n at the end that has be truncated\n",
    "for i,value in enumerate(values_column3):\n",
    "    values_column3[i-1] = values_column3[i-1][0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now create the data frame with the data we have obtained**\n",
    "**Then we will wrangle the data, so we can better process it in a later stage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame\n",
    "df_values = np.array([values_column1,values_column2,values_column3]).transpose()\n",
    "Neighborhoods_CN = pd.DataFrame(data = df_values,columns = columns_headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all the rows with 'Borough' = Not assinged\n",
    "Neighborhoods_CN['Borough'].replace(to_replace='Not assigned',value = np.nan,inplace=True)\n",
    "Neighborhoods_CN.dropna(inplace=True)\n",
    "Neighborhoods_CN.reset_index(drop = True,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_postcodes = Neighborhoods_CN['Postcode'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a list with the boolean values for unique postcodes\n",
    "length = len(Neighborhoods_CN['Postcode'])\n",
    "\n",
    "for i in range(0,length):\n",
    "    filter_DF.append(Neighborhoods_CN['Postcode'][i] in unique_postcodes)\n",
    "    if Neighborhoods_CN['Postcode'][i] in unique_postcodes:     \n",
    "        unique_postcodes.pop(unique_postcodes.index(Neighborhoods_CN['Postcode'][i]))\n",
    "        \n",
    "filter_DF_reversed = list(~np.array(filter_DF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netze\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\netze\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# creating two new data frames. The first one with single postcodes.\n",
    "# The second one with the rest of the intial data frame\n",
    "Neighborhoods_CN_filtered1 = Neighborhoods_CN[filter_DF]\n",
    "Neighborhoods_CN_filtered2 = Neighborhoods_CN[filter_DF_reversed]\n",
    "\n",
    "for val in Neighborhoods_CN_filtered2['Postcode'].values.tolist():\n",
    "    for i in Neighborhoods_CN_filtered2[Neighborhoods_CN_filtered2['Postcode']==val].index:\n",
    "        row = Neighborhoods_CN_filtered1[Neighborhoods_CN_filtered1['Postcode']==val].index[0]\n",
    "        val_to_add =  Neighborhoods_CN_filtered2.loc[i,'Neighbourhood']\n",
    "        Neighborhoods_CN_filtered1.loc[row,'Neighbourhood'] = Neighborhoods_CN_filtered1.loc[row,'Neighbourhood'] + ', ' + val_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netze\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3795: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n"
     ]
    }
   ],
   "source": [
    "# now we append the Neighbourhood of the second data frame to the first one for the respective postcodes \n",
    "for i in Neighborhoods_CN_filtered1[Neighborhoods_CN_filtered1['Neighbourhood'] == 'Not assigned']['Borough'].index:\n",
    "    val = Neighborhoods_CN_filtered1.loc[i,'Borough']\n",
    "    Neighborhoods_CN_filtered1.replace(to_replace='Not assigned', value=val, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 3)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neighborhoods_CN_filtered1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
